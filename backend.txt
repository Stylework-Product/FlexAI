import os
import re
import json
<<<<<<< HEAD:backend.py
import asyncio
import pandas as pd
=======
from typing import Optional, List, Dict, Any
import os
import requests
from connection import ChatSession, create_new_session, get_existing_session
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
from datetime import datetime
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, Body, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import google.generativeai as genai
<<<<<<< HEAD:backend.py
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from connection import create_new_session, get_existing_session
import urllib.parse

load_dotenv()

app = FastAPI()
=======
from google.generativeai import types
import io
from langchain.text_splitter import CharacterTextSplitter
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain_community.vectorstores import FAISS
from langchain.embeddings.base import Embeddings
from langchain.llms.base import LLM
from typing import Optional, List
import pickle
from embeddings import GeminiEmbeddings
from connection_app import load_embeddings
from embedding_manager import list_files_in_folder, EMBEDDING_NAME, folder_id
from fastapi.responses import StreamingResponse
import asyncio

app = FastAPI(title="FlexAI", description="An AI-assistant for workspace booking")
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MAX_HISTORY_MESSAGES = int(os.getenv("MAX_HISTORY_MESSAGES"))
MIN_SIMILARITY_SCORE = float(os.getenv("MIN_SIMILARITY_SCORE"))

genai.configure(api_key=GEMINI_API_KEY)

<<<<<<< HEAD:backend.py
# URL generation mappings
=======
async def animate(text: str):
    for char in text:
        yield char
        await asyncio.sleep(0.005)  # adjust speed here

def print_text_animated(text: str):
    return StreamingResponse(animate(text), media_type="text/plain")

>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
WORKSPACE_TYPE_SLUG = {
    "day pass": "day-pass",
    "meeting room": "meeting-rooms",
    "private cabin": "private-office-cabin",
    "dedicated desk": "dedicated-desk",
    "open desk": "open-desk",
    "virtual office": "virtual-office"
}

VALID_CITIES = {
    "agartala", "agra", "ahmedabad", "ajmer", "akola", "ambala", "amritsar", "anand", "ankleshwar", 
    "balasinor", "bareilly", "bengaluru", "bhagalpur", "bhopal", "bhubaneshwar", "chakpachuria", 
    "chandigarh", "chennai", "chittoor", "coimbatore", "deesa", "dehradun", "delhi nct", "dhanbad", 
    "dharamshala", "dhule", "dimapur", "dubai", "durg", "east godavari", "east khasi hills", 
    "ernakulam", "faridabad", "gautam buddha nagar", "ghaziabad", "goa", "gorakhpur", "guntur", 
    "gurgaon", "guwahati", "gwalior", "hyderabad", "imphal west", "indore", "jabalpur", "jaipur", 
    "jalandhar", "jammu", "jamshedpur", "jodhpur", "kakkanad", "kanpur nagar", "kochi", "kolkata", 
    "kothaguda", "kottayam", "kozhikode", "kurnool", "lucknow", "ludhiana", "madurai", "mangalore", 
    "mohali", "mumbai", "mysuru (mysore)", "nagpur", "nandurbar", "nashik", "navi mumbai", "noida", 
    "palakkad", "panaji", "panchkula", "patna", "pondicherry", "prayagraj", "pune", "raipur", 
    "rajkot", "ranchi", "ratlam", "sahibzada ajit singh nagar (mohali)", "salem", "sangli", "sikar", 
    "siliguri", "surat", "thane", "thiruvananthapuram", "tiruchirappalli", "udaipur", "ujjain", 
    "vadodara", "varanasi", "vellore", "vijayawada", "visakhapatnam", "warangal (urban)", "zirakpur"
}

CATEGORY_IDS = {
    "standard": "63c8ef67b593488ed624bff4",
    "silver": "63c8ef6eb593488ed624bff5",
    "gold": "63c8ef74b593488ed624bff6",
    "platinum": "63c8ef7ab593488ed624bff7",
    "platinum+": "659c22a8c5737f2fe35d0d37"
}

SORT_BY_PRICE = {
    "low to high": "Price%20(Low%20to%20High)",
    "high to low": "Price%20(High%20to%20Low)"
}

<<<<<<< HEAD:backend.py
def normalize_city_name(city: str) -> str:
    """Normalize city name for URL generation"""
    if not city:
        return ""
    
    city_lower = city.lower().strip()
    
    # Handle special cases
    if city_lower in ["delhi", "new delhi"]:
        return "delhi-nct"
    elif city_lower in ["mysore", "mysuru"]:
        return "mysuru-mysore"
    elif city_lower in ["mohali"]:
        return "sahibzada-ajit-singh-nagar-mohali"
    
    # Replace spaces with hyphens and handle special characters
    normalized = city_lower.replace(" ", "-").replace("(", "").replace(")", "")
    
    # Check if normalized city exists in our valid cities list
    if normalized in [c.replace(" ", "-").replace("(", "").replace(")", "") for c in VALID_CITIES]:
        return normalized
    
    return city_lower.replace(" ", "-")

def extract_workspace_info_from_recommendations(recommendations_text: str) -> Dict[str, Any]:
    """Extract workspace information from recommendations text for URL generation"""
    info = {
        "workspace_types": set(),
        "cities": set(),
        "categories": set(),
        "sort_preference": None
    }
    
    if not recommendations_text:
        return info
    
    lines = recommendations_text.split('\n')
    
    for line in lines:
        line_lower = line.lower()
        
        # Extract workspace types
        for workspace_type in WORKSPACE_TYPE_SLUG.keys():
            if workspace_type in line_lower:
                info["workspace_types"].add(workspace_type)
        
        # Extract cities
        for city in VALID_CITIES:
            if city in line_lower:
                info["cities"].add(city)
        
        # Extract categories
        for category in CATEGORY_IDS.keys():
            if category in line_lower:
                info["categories"].add(category)
        
        # Extract sort preferences
        if "price" in line_lower:
            if "low to high" in line_lower or "ascending" in line_lower:
                info["sort_preference"] = "low to high"
            elif "high to low" in line_lower or "descending" in line_lower:
                info["sort_preference"] = "high to low"
    
    return info

def generate_stylework_url(workspace_info: Dict[str, Any]) -> str:
    """Generate Stylework.city URL based on extracted information"""
    if not workspace_info["workspace_types"] or not workspace_info["cities"]:
        return ""
    
    # Use the first workspace type and city found
    workspace_type = list(workspace_info["workspace_types"])[0]
    city = list(workspace_info["cities"])[0]
    
    # Get the slug for workspace type
    workspace_slug = WORKSPACE_TYPE_SLUG.get(workspace_type, "day-pass")
    
    # Normalize city name
    city_slug = normalize_city_name(city)
    
    # Build base URL
    base_url = f"https://www.stylework.city/{workspace_slug}/{city_slug}"
    
    # Add query parameters
    params = []
    
    # Add categories
    if workspace_info["categories"]:
        for category in workspace_info["categories"]:
            category_id = CATEGORY_IDS.get(category)
            if category_id:
                params.append(f"category={category_id}")
    
    # Add sort preference
    if workspace_info["sort_preference"]:
        sort_param = SORT_BY_PRICE.get(workspace_info["sort_preference"])
=======
def get_day_pass_budget(budget):
    """Map the given budget to the nearest lower day pass price point"""
    if budget < 200:
        return None
    elif 200 <= budget < 400:
        return 200
    elif 400 <= budget < 600:
        return 400
    elif 600 <= budget < 800:
        return 600
    elif 800 <= budget < 1000:
        return 800
    elif 1000 <= budget < 1200:
        return 1000
    elif 1200 <= budget < 1400:
        return 1200
    elif 1400 <= budget < 1600:
        return 1400
    elif 1600 <= budget < 1800:
        return 1600
    elif 1800 <= budget <= 2000:
        return 1800
    else:
        return 2000 

def get_space_budget(budget):
    """Map the given budget to the nearest lower space budget price point"""
    if budget < 3000:
        return None
    elif 3000 <= budget < 6000:
        return 3000
    elif 6000 <= budget < 9000:
        return 6000
    elif 9000 <= budget < 12000:
        return 9000
    elif 12000 <= budget < 15000:
        return 12000
    elif 15000 <= budget < 18000:
        return 15000
    elif 18000 <= budget <= 20000:
        return 18000
    else:
        return 20000

def generate_stylework_url(city: str, workspace_type: str, bundle: List[str], sort_by_price: bool, budget: int) -> str:
    """Generate Stylework.city URL based on extracted information"""
    city_slug = city.lower().replace(' ', '-')
    if workspace_type == "private cabin":
        type_slug = "private-office-cabins"
    else:
        type_slug = workspace_type.lower().replace(' ', '-')

    if not type_slug or not city_slug:
        return ""
    
    base_url = f"https://www.stylework.city/{type_slug}/{city_slug}"
    
    params = []
    
    if bundle:
        for category in bundle:
            category_id = CATEGORY_IDS.get(category)
            if category_id:
                params.append(f"category={category_id}")
    if budget:
        if workspace_type == "day pass":
            budget_range = get_day_pass_budget(budget)
            if budget_range:
                params.append(f"budget={budget_range}")
        else:
            space_range = get_space_budget(budget)
            if space_range:
                params.append(f"budget={space_range}")
    # Add sort preference
    if sort_by_price:
        sort_param = SORT_BY_PRICE.get("low to high")
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
        if sort_param:
            params.append(f"sortBy={sort_param}")
    
    # Combine URL with parameters
    if params:
        base_url += "?" + "&".join(params)
    
    return base_url

<<<<<<< HEAD:backend.py
async def animate(text: str):
    for char in text:
        yield char
        await asyncio.sleep(0.005)  # adjust speed here

def print_text_animated(text: str):
    return StreamingResponse(animate(text), media_type="text/plain")

=======
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
# Gemini set up for pdf document answering
INITIAL_PROMPT = (
    "You are an expert assistant in helping user answer questions based on the document."
    "Answer the questions based on the provided document. But do not specify in the response 'based on the document' just answer like a normal assistant."
    "Also have a friendly conversation with user. All questions will not be related to the document."
<<<<<<< HEAD:backend.py
=======
    "If the user query asked is not available within your domain knowledge then response should be - You can contact the operation team regarding this query at operations@stylework.city!"
    "REQUIRED: Make sure the responses are displayed in a neat format with proper spacing and formatting:"
    "- Use bullet points (•) for lists"
    "- Use **bold** for headings and important terms"
    "- Add proper line breaks between sections"
    "- Remove unnecessary spaces and formatting issues"
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
    "Be concise and accurate."
    "IMPORTANT: Maintain continuity with previous messages"
)

<<<<<<< HEAD:backend.py
class GeminiLLM:
    def __init__(self, model: str = "models/gemini-2.0-flash-lite", initial_prompt: str = INITIAL_PROMPT):
        self.model = model
        self.initial_prompt = initial_prompt

    def _call(self, prompt: str) -> str:
=======
class GeminiLLM(LLM):
    model: str = "models/gemini-2.0-flash-lite"
    initial_prompt: str = INITIAL_PROMPT
    
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
        full_prompt = f"{self.initial_prompt}\n\n{prompt}"
        model = genai.GenerativeModel(self.model)
        response = model.generate_content(full_prompt)
        return response.text

<<<<<<< HEAD:backend.py
# Router prompt for intent classification
=======
    @property
    def _llm_type(self) -> str:
        return "gemini-llm"

# splits the document into chunks
def get_text_chunks(text: str) -> List[str]:
    splitter = CharacterTextSplitter(separator="\n", chunk_size=1000, chunk_overlap=200)
    return splitter.split_text(text)

# initializes a llm gemini model and creates a memory for it
def get_conversation_chain(vectorstore, initial_prompt=INITIAL_PROMPT):
    llm = GeminiLLM(initial_prompt=initial_prompt)
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    return ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), memory=memory)

# recives the user query and produces a response
def handle_userinput(user_question, conversation, chat_history):
    if not user_question or not conversation:
        return "PDF not loaded yet."
    history = [(msg["role"], msg["parts"][0]) for msg in chat_history if msg.get("parts")]
    response = conversation.invoke({
        "question": user_question,
        "chat_history": history
    })
    bot_msg = response.get("answer", "You can contact the operation team regarding this query at operations@stylework.city!")
    return bot_msg

# format for user input
class UserInput(BaseModel):
    workspaceName: Optional[str] = ''
    city: str
    area: Optional[List[str]] = []
    workspaceType: str
    size: Optional[int] = 1
    amenities: Optional[List[str]] = []
    bundle: Optional[List[str]] = []
    budget: Optional[int] = 0
    rating: Optional[int] = 0
    offeringType: Optional[str] = ''
    placeType: Optional[str] = ''

# format for chat message
class ChatMessage(BaseModel):
    id: str
    text: str
    sender: str
    timestamp: str

class ChatRequest(BaseModel):
    user_message: str
    chat_history: List[ChatMessage]
    session_id: Optional[str] = None

global_sessions = {}

# retrieve session id
def get_session(session_id: str = None, user_id: str = None):
    if session_id:
        if session_id in global_sessions:
            session = global_sessions[session_id]
        else:
            session = get_existing_session(session_id)
            if session:
                global_sessions[session_id] = session
            else:
                # Return None if session not found
                return None
    else:
        # Don't create sessions here - only retrieve existing ones
        return None

    return session

@app.get("/session/{session_id}")
async def get_session_data(session_id: str):
    """Get session data by ID"""
    if session_id in global_sessions:
        return global_sessions[session_id].__dict__
    return {"error": "Session not found"}

@app.delete("/session/{session_id}")
async def delete_session(session_id: str):
    """Delete a session"""
    if session_id in global_sessions:
        del global_sessions[session_id]
        return {"message": "Session deleted"}
    return {"error": "Session not found"}

class UserInfo(BaseModel):
    name: str
    email: str
    phone: str

class SessionRequest(BaseModel):
    user_info: UserInfo

@app.post("/session")
async def create_session(data: SessionRequest):
    user_info = data.user_info
    name = user_info.name.strip().lower().replace(" ", "_")
    email = user_info.email.strip().lower()
    user_id = f"{name}_{email}"
    
    # Create new session and store in global sessions
    session = create_new_session(user_id=user_id)
    global_sessions[session.session_id] = session
    
    print("[DEBUG] Created session:", session.session_id, "for user_id:", user_id)

    return {"session_id": session.session_id, "user_id": user_id}

# fetch the dataset from google sheet
def fetch_sheet_as_df(sheet_id, sheet_name, api_key):
    url = (
        f"https://sheets.googleapis.com/v4/spreadsheets/{sheet_id}/values/{sheet_name}?key={api_key}"
    )
    resp = requests.get(url)
    resp.raise_for_status()
    data = resp.json()
    values = data.get("values", [])
    if not values:
        raise ValueError("No data found in the sheet.")
    df = pd.DataFrame(values[1:], columns=values[0])
    return df


if SHEET_API_KEY and SHEET_ID and SHEET_NAME:
    df = fetch_sheet_as_df(SHEET_ID, SHEET_NAME, SHEET_API_KEY)
else:
    print("Incorrect credentials - SHEET_API_KEY, SHEET_ID and SHEET_NAME")

# data processing of dataset
numeric_columns = [
    'DAY PASS',
    'FLEXI DESK _MONTHLY',
    'DD_MONTHLY',
    'PC_MONTHLY',
    'review_count',
    'seats_available'
]

for col in numeric_columns:
    df[col] = pd.to_numeric(df[col])

df['avg_rating'] = pd.to_numeric(df['avg_rating']).astype(float)

def clean_amenity(a):
    return re.sub(r'[\[\]"\']', '', a).strip().lower()

df['Unboxed Coworking'] = df['Unboxed Coworking'].str.strip().str.lower()
df['CITY'] = df['CITY'].str.strip().str.lower()
df['STATUS'] = df['STATUS'].str.strip().str.lower()
df['CATEGORY AS PER PRICING'] = df['CATEGORY AS PER PRICING'].str.strip().str.lower()
df['CATEGORY AS PER SAP'] = df['CATEGORY AS PER SAP'].str.strip().str.lower()
if 'AREA' in df.columns:
    df['AREA'] = df['AREA'].str.strip().str.lower()

df['AMENITIES'] = df['AMENITIES'].apply(lambda x: [clean_amenity(s) for s in str(x).split(',')])

city_alias_map = {}
for city in df['CITY'].unique():
    city_alias_map[city] = city
    city_lower = city.strip().lower()
    # Only map well-known aliases, not substrings
    if city_lower == "delhi nct":
        city_alias_map["delhi"] = city
        city_alias_map["new delhi"] = city
    elif city_lower == "delhi":
        city_alias_map["new delhi"] = city
    if city_lower == "gurgaon":
        city_alias_map["gurugram"] = city
    if city_lower == "gurugram":
        city_alias_map["gurgaon"] = city
    if city_lower == "bengaluru":
        city_alias_map["bangalore"] = city
        city_alias_map["bangaluru"] = city
    if city_lower == "bangalore":
        city_alias_map["bengaluru"] = city
    if city_lower == "mumbai":
        city_alias_map["bombay"] = city
    if city_lower == "bombay":
        city_alias_map["mumbai"] = city
    if city_lower == "sahibzada ajit singh nagar (mohali)":
        city_alias_map["mohali"] = city
    if city_lower == "mysuru (mysore)":
        city_alias_map["mysore"] = city
        city_alias_map["mysuru"] = city
    if city_lower == "warangal (urban)":
        city_alias_map["warangal"] = city

def format_workspace_recommendations(result: List[Dict[str, Any]]) -> str:
    if not result:
        return "\n\nSorry, I couldn't find any workspaces matching your specific criteria. You might want to try adjusting your requirements."

    recommendations_text = "\n\nHere are some workspace recommendations for you:\n"

    for idx, rec in enumerate(result, 1):
        recommendations_text += f"\n{idx}. {rec['name'].title()}"

        if rec.get('area'):
            recommendations_text += f" (Area: {rec['area'].title()})"

        recommendations_text += f"\n   Address: {rec.get('address', 'Not available')}"

        recommendations_text += f"\n   Workspace Type: {rec.get('workspace_type', '').title()}"

        offerings = rec.get('offerings')
        if offerings:
            recommendations_text += f"\n   Offerings: {offerings}"

        amenities = rec.get('amenities')
        if amenities:
            amenities_str = ', '.join(amenities)
            recommendations_text += f"\n   Amenities: {amenities_str}"

        if rec.get('seats_available'):
            recommendations_text += f"\n   Seats Available: {rec['seats_available']}"

        if rec.get('rating'):
            recommendations_text += f"\n   Rating: {rec['rating']}"

        if rec.get('category'):
            recommendations_text += f"\n   Category: {rec['category']}"

        if rec.get('price'):
            recommendations_text += f"\n   Price: ₹{rec['price']}"

        if rec.get('similarity_score', 0) > 70:
            recommendations_text += f"\n   Similarity Score: {rec['similarity_score']}%"

        # Constructing the dynamic workspace link
        name_slug = rec['name'].lower().replace(' ', '-').replace('&', 'and')
        city_slug = rec.get('city', '').lower().replace(' ', '-')
        workspace_type = rec.get('workspace_type', '').lower()

        if workspace_type == "private cabin":
            type_slug = "private-office-cabins"
        else:
            type_slug = workspace_type.replace(' ', '-')

        link = f"https://www.stylework.city/{type_slug}/{city_slug}/{name_slug}"
        recommendations_text += f"\n   Link: [View Details]({link})\n"

    return recommendations_text

# setup for router gemini - which routes the user query to 3 different gemini models
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
GEMINI_ROUTER_PROMPT = """
    You are a router assistant. Given a user message, decide if it is about:
    - "pdf" → if the question refers to anything about the company or functionalities (eg what is fixed memebership, what is flex ai, what are the functionalities of ai etc.).
    - "workspace" → if it refers to workspace booking, area, city, location, budget, seats, coworking, offices, pricing etc.
    - "general" → if it's a general conversation or unrelated (greeting, jokes, questions about you, etc.)

    Respond with only one word: "pdf", "workspace", or "general"

    User message: {message}
"""

def classify_intent_with_gemini(user_message: str) -> str:
    try:
        router_model = genai.GenerativeModel("gemini-2.0-flash-lite")
        prompt = GEMINI_ROUTER_PROMPT.format(message=user_message.strip())
        response = router_model.generate_content(prompt)
        intent = response.text.strip().lower()
        
        if intent in ["pdf", "workspace", "general"]:
            return intent
        else:
            return "general"
    except Exception as e:
        print(f"[ERROR] Intent classification failed: {e}")
        return "general"

@app.post("/session")
async def create_session(user_info: dict = Body(..., embed=True)):
    try:
        session = create_new_session(user_info.get("email", ""))
        return {"session_id": session.session_id, "user_id": session.user_id}
    except Exception as e:
        print(f"[ERROR] Session creation failed: {e}")
        raise HTTPException(status_code=500, detail="Failed to create session")

@app.post("/multimodal_agent")
<<<<<<< HEAD:backend.py
async def multimodal_agent(
=======
async def multimodal_agent_router(
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
    user_message: str = Body(..., embed=True),
    chat_history: list = Body([], embed=True),
    session_id: str = Body(..., embed=True),
    user_id: str = Body(..., embed=True)
):
    intent = classify_intent_with_gemini(user_message)
    print(f"[DEBUG] Classified intent: {intent}")
    
    if intent == "pdf":
        return await pdf_chat(user_message=user_message, chat_history=chat_history, session_id=session_id, user_id=user_id)
    elif intent == "workspace":
        return await gemini_chat(user_message=user_message, chat_history=chat_history, session_id=session_id, user_id=user_id)
    else:
        return await general_chat(user_message=user_message, chat_history=chat_history, session_id=session_id, user_id=user_id)

@app.post("/pdf_chat")
async def pdf_chat(
    user_message: str = Body(..., embed=True),
    chat_history: list = Body([], embed=True),
    session_id: str = Body(..., embed=True),
    user_id: str = Body(..., embed=True)
):
    session = get_existing_session(session_id)
    if not session:
        return {"error": f"Session {session_id} not found. Please create a new session."}

    try:
        llm = GeminiLLM()
        reply_text = llm._call(user_message)
        
        session.add_user_message(user_message)
        session.add_assistant_message(reply_text, {}, [])
        
        timestamp = datetime.now().isoformat()
    except Exception as e:
        print(f"[ERROR] PDF chat failed: {e}")
        reply_text = "You can contact the operation team regarding this query at operations@stylework.city!"
    
    print(f"[DEBUG] Gemini Response: {reply_text}")
    return print_text_animated(reply_text)
<<<<<<< HEAD:backend.py
=======
    #return {"reply": reply_text, "session_id": session_id, "user_id": user_id, "timestamp": timestamp, "chat_history": session.get_messages() if session else []}
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt

# General chat prompt
GENERAL_PROMPT = """
    You are FlexAI, a friendly assistant for Styleworks. Greet users, answer general questions, and guide them towards workspace booking or learning about Styleworks and Flexboard features.
    If the user asks about booking, features, or the platform, offer to help or provide information.
    Do not answer workspace-specific queries here; only handle general conversation.
    
    IMPORTANT: Format your responses properly:
    - Use **bold** for headings and important terms
    - Add proper line breaks between sections
<<<<<<< HEAD:backend.py
    - Keep responses concise and friendly
    - IMPORTANT: Maintain continuity with previous messages
=======
    - Remove unnecessary spaces and formatting issues
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt

    User message: {message}
"""

@app.post("/general_chat")
async def general_chat(
    user_message: str = Body(..., embed=True),
    chat_history: list = Body([], embed=True),
    session_id: str = Body(..., embed=True),
    user_id: str = Body(..., embed=True)
):
    session = get_existing_session(session_id)
    if not session:
        return {"error": f"Session {session_id} not found. Please create a new session."}

    model = genai.GenerativeModel("gemini-2.0-flash-lite")
    prompt = GENERAL_PROMPT.format(message=user_message.strip())

    try:
        response = model.generate_content(prompt)
        reply_text = response.text
        
        session.add_user_message(user_message)
        session.add_assistant_message(reply_text, {}, [])
        
        timestamp = datetime.now().isoformat()
    except Exception as e:
        print(f"[ERROR] General chat failed: {e}")
        reply_text = "You can contact the operation team regarding this query at operations@stylework.city!"
        timestamp = None

    return print_text_animated(reply_text)
<<<<<<< HEAD:backend.py
=======
    #return {"reply": reply_text, "timestamp": timestamp}
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt

# setup for the recommendation gemini model
df = pd.read_csv("updated_dataset.csv")

GEMINI_PROMPT = (
    "You are FlexAI, a workspace booking assistant for Stylework. Your role is to:\n\n"
    "CRITICAL INSTRUCTIONS:\n"
    "1. NEVER provide workspace recommendations directly in your response\n"
    "2. NEVER include workspace names, addresses, or specific details in your conversational reply\n"
    "3. DO NOT provide any workspace recommendations in your response\n"
    "4. Your ONLY job is to:\n"
    "	- Have a friendly conversation with the user like basic greetings, conversation etc. While having friendly conversation do not include JSON in your reply as it is not a workspace query.\n"
    "	- Extract the following information and format as JSON: workspaceName, city, area, workspaceType (options: day pass, flexi desk, dedicated desk, private cabin), size, amenities (list), bundle (also called category) (list - options: standard, silver, gold, platinum, platinum+), budget, rating, offeringType (options: day pass, flexi desk, dedicated desk, private cabin), placeType (cafe, resturant, bank etc.)\n"
    "	- Answer users' questions about the platform and the recommendations provided (eg if they ask about what amenities are provided by a specific workspace or the price of a workspace you should be able to answer it based on the information provided) and this is NOT a request for recommendation engine.\n"
    "	- If the user is asking for workspace recommendations, respond conversationally (e.g., 'Let me find some great workspaces for you!') and include the JSON\n\n"
    "RESPONSE FORMAT:\n"
    "- Provide a friendly, conversational response\n"
    "- If extracting requirements, add JSON at the end in this exact format:\n"
    "```json\n{\"workspaceName\": \"\", \"city\": \"\", \"area\": \"\", \"workspaceType\": \"\", \"size\": \"\", \"amenities\": [], \"bundle\": [], \"budget\": \"\", \"rating\": \"\", \"offeringType\": \"\", \"placeType\": \"\"}\n```\n\n"
    "IMPORTANT: Maintain continuity with previous messages\n"
    "User message: {message}\n"
    "Chat history: {history}"
)

@app.post("/gemini_chat")
async def gemini_chat(
    user_message: str = Body(..., embed=True),
    chat_history: list = Body([], embed=True),
    session_id: str = Body(..., embed=True),
    user_id: str = Body(..., embed=True)
):
    session = get_existing_session(session_id)
    if not session:
        return {"error": f"Session {session_id} not found. Please create a new session."}
<<<<<<< HEAD:backend.py
=======
    
    session_id = session.session_id
    print(f"Session ID: {session_id}")

    session.add_user_message({
        "type": "user",
        "content": user_message 
    })

    system_prompt = (
        "You are FlexAI, a helpful assistant for a workspace booking platform called Styleworks. Your main job is to assist users in searching for and booking workspaces.\n"
        "Stylework is India's largest flexible workspace provider, offering a robust solution for businesses of various sizes. With a presence in 100+ cities in India, we connect individuals, startups, and enterprises to a diverse network of ready-to-move-in coworking and managed office spaces."
        "CRITICAL INSTRUCTIONS:\n"
        "1. DO NOT filter, search, or recommend any workspaces yourself\n"
        "2. DO NOT mention specific workspace names, addresses, or details\n"
        "3. DO NOT provide any workspace recommendations in your response\n"
        "4. Your ONLY job is to:\n"
        "	- Have a friendly conversation with the user like basic greetings, conversation etc. While having friendly conversation do not include JSON in your reply as it is not a workspace query.\n"
        "	- Extract the following information and format as JSON: workspaceName, city, area, workspaceType (options: day pass, flexi desk, dedicated desk, private cabin), size, amenities (list), bundle (also called category) (list - options: standard, silver, gold, platinum, platinum+), budget, rating, offeringType (options: day pass, flexi desk, dedicated desk, private cabin), placeType (cafe, resturant, bank etc.)\n"
        "	- Answer users' questions about the platform and the recommendations provided (eg if they ask about what amenities are provided by a specific workspace or the price of a workspace you should be able to answer it based on the information provided) and this is NOT a request for recommendation engine.\n"
        "	- Extract search parameters from their message\n"
        "	- Let the recommendation engine handle ALL workspace suggestions\n"
        "	- Make sure user provides city and type of workspace they are looking for, if not provided in the start then ask them these questions one after another. After the initial requirements are provided ask them if they have a specific requirement in amentities, budget, area etc.\n"
        "	- If the workspace type is not specified in the start but is mentioned later, update the search parameters accordingly but if it is specified in the start and not explicitly told to change later then keep it same.\n"
        "	- If the user specifies a workspace type in the start, use that type for the search but if they mention it later then update the search parameters(workspaceType) accordingly.\n\n"
        "5. DO NOT skip JSON during workspace-related user message just because it was already provided earlier. Always repeat the full updated JSON when any user parameter changes. ONLY for workspace requests\n"
        "6. When user asks the price of a workspace based on the offering - the recommendation engine has the capability to do so. DO NOT think on your own."
        "7. When a user asks about workspaces:\n"
        "	- Acknowledge their request professionally\n"
        "	- If information is missing, set to null or empty values (0 for integer columns and [] for list columns)\n"
        "	- DO NOT include any specific workspace details or recommendations\n"
        "	- Extract the input parameters from the user message and format them as JSON.\n\n"
        "8.Understand important keywords:\n"
        "	- 'day pass' means a single day access\n"
        "	- 'flexi desk' means a flexible desk for a month\n"
        "	- 'dedicated desk' means a personal desk for a month\n"
        "	- 'private cabin' means a coworking space or workspace or office or private office or cabin or shared office for a month\n"
        "	- 'bundle' refers to the pricing category (standard, silver, gold, platinum, platinum+)\n"
        "	- 'budget' refers to the maximum price they are willing to pay\n"
        "	- 'offerings' refers to the type of desk types (day pass, flexi desk, dedicated desk, private cabin) provided by the workspace\n\n"
        "   - 'placeType' refers to the type of place user wants the workspace to be near by (cafe, restaurant, bank etc)\n"
        "9.If user mentions any words like 'office', 'coworking space', 'shared office', 'workspace', 'desk', 'cabin', 'private office', etc., consider it as a workspace search request unless they ask about the services provided - understand if the request is a question or a statement and then decide accordingly.\n\n"
        "10.If the user wants to BOOK a workspace - ask the user for details (such as name, email, number of seats required, joining date of space etc or any other appropriate details needed) - only after the user had requested to look for a workspace, if workspace request was not iniitalized then go for the request. After collecting the details mention that the details are sent to the operations team and they will contact the user soon regarding the workspace query."
        "11.Make sure the responses are displayed in a neat format with proper spacing and formatting:"
        "   - Use bullet points (•) for lists"
        "   - Use **bold** for headings and important terms"
        "   - Add proper line breaks between sections"
        "   - Remove unnecessary spaces and formatting issues"
        "IMPORTANT: Any user query which is not in the 11 points functionality of the chatbot display the bot message - You can contact the operation team regarding this query at operations@stylework.city!"
        "IMPORTANT: Maintain continuity with previous messages. If the user refers to something mentioned earlier, use that context in your response.\n\n"
        f"User message: {user_message}\n"
        f"Chat history: {chat_history}\n"
        "-- JSON Enforcement Rule --"
        "When the user gives new input (like budget, location, size, etc.), REPLACE the previous value and OUTPUT the FULL updated JSON again."
        "Example - User: My budget is 450 rupees"
        "You must respond with:"
        """{
        "workspaceName": "",
        "city": "delhi",
        "area": [],
        "workspaceType": "day pass",
        "size": 1,
        "amenities": [],
        "bundle": ["gold"],
        "budget": 450,
        "rating": 0,
        "offeringType": "day pass",
        "placeType": "metro station"
        }"""
        "Always update the full structure. NEVER skip this JSON - for workspace request ONLY."
    )
    filtered_history = [msg for msg in chat_history if msg.get("sender") == "user"]
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt

    try:
        gemini_model = genai.GenerativeModel("gemini-2.0-flash-lite")

        # Build Gemini SDK-compatible chat history
        history_text = ""
        for msg in chat_history[-MAX_HISTORY_MESSAGES:]:
            role = "User" if msg.get("sender") == "user" else "Assistant"
            history_text += f"{role}: {msg.get('text', '')}\n"

        prompt = GEMINI_PROMPT.format(message=user_message, history=history_text)
        response = gemini_model.generate_content(prompt)
        gemini_reply = response.text

        session.add_user_message(user_message)

        # Extract JSON if present
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', gemini_reply, re.DOTALL)
        extracted_json = {}
        
        if json_match:
            try:
                extracted_json = json.loads(json_match.group(1))
                print(f"[DEBUG] Extracted JSON: {extracted_json}")
            except json.JSONDecodeError as e:
                print(f"[ERROR] JSON parsing failed: {e}")

        # Remove JSON from conversational reply
        conversational_reply = re.sub(r'```json\s*\{.*?\}\s*```', '', gemini_reply, flags=re.DOTALL).strip()
        
        final_reply = conversational_reply

        # If we have extracted requirements, find recommendations
        if extracted_json and any(extracted_json.values()):
            print(f"[DEBUG] Processing workspace search with: {extracted_json}")
            
            # Filter dataframe based on extracted criteria
            df_filtered = df.copy()
            
            # Apply filters
            if extracted_json.get("city"):
                city_filter = extracted_json["city"].lower()
                df_filtered = df_filtered[df_filtered['City'].str.lower().str.contains(city_filter, na=False)]
            
            if extracted_json.get("workspaceType"):
                workspace_type = extracted_json["workspaceType"].lower()
                df_filtered = df_filtered[df_filtered['Workspace Type'].str.lower().str.contains(workspace_type, na=False)]
            
            if extracted_json.get("bundle"):
                bundles = [b.lower() for b in extracted_json["bundle"]]
                bundle_filter = '|'.join(bundles)
                df_filtered = df_filtered[df_filtered['Bundle'].str.lower().str.contains(bundle_filter, na=False)]

            if df_filtered.empty:
                recommendations_text = "\n\nSorry, I couldn't find any workspaces matching your criteria. You might want to try adjusting your requirements."
                final_reply += recommendations_text
                return print_text_animated(final_reply)

            # Check for location-based query (e.g., "show me day pass in delhi near a cafe")
<<<<<<< HEAD:backend.py
            place_type = extracted_json.get("placeType", "").lower()
            if place_type and place_type.strip():
                print(f"[DEBUG] Location-based query detected with place_type: {place_type}")
                response = await nearbyplaces_chat(user_message, df_filtered, chat_history, session_id, user_id, place_type)
                df_filtered = response["filtered_results"]
=======
            location_based_query = False
            place_type = None
            
            # First check if we have placeType in the extracted JSON
            if extracted and 'placeType' in extracted and extracted['placeType']:
                place_type = extracted['placeType']
                location_based_query = True
            
            if location_based_query and place_type and city:
                print(f"Workspace type: {workspace_type}, City: {city}, Place type: {place_type}")
                response = await nearbyplaces_chat(user_message, df_filtered, chat_history, session_id, user_id, place_type)
                df_filtered = response["filtered_results"]
                #print(df_filtered.head(10).to_string(max_colwidth=200, max_rows=None, max_cols=None))
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt

            # --- Feature similarity calculations (always use all available features) ---
            feature_columns = ['Workspace Type', 'Bundle', 'Amenities', 'City', 'Area']
            available_features = [col for col in feature_columns if col in df_filtered.columns]
            
            if available_features:
                # Create feature text for similarity calculation
                df_filtered['feature_text'] = df_filtered[available_features].fillna('').apply(
                    lambda x: ' '.join(x.astype(str)), axis=1
                )
                
<<<<<<< HEAD:backend.py
                # Create query text from extracted JSON
                query_parts = []
                for key, value in extracted_json.items():
                    if value:
                        if isinstance(value, list):
                            query_parts.extend([str(v) for v in value])
                        else:
                            query_parts.append(str(value))
                
                query_text = ' '.join(query_parts)
                
                if query_text.strip():
                    # Calculate similarity scores
                    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))
                    all_texts = df_filtered['feature_text'].tolist() + [query_text]
                    tfidf_matrix = vectorizer.fit_transform(all_texts)
                    
                    # Calculate similarity between query and each workspace
                    query_vector = tfidf_matrix[-1]
                    workspace_vectors = tfidf_matrix[:-1]
                    similarities = cosine_similarity(query_vector, workspace_vectors).flatten()
                    
                    # Add similarity scores to dataframe
                    df_filtered['similarity_score'] = similarities * 100
                    
                    # Filter by minimum similarity score and sort
                    df_filtered = df_filtered[df_filtered['similarity_score'] >= MIN_SIMILARITY_SCORE]
                    df_filtered = df_filtered.sort_values('similarity_score', ascending=False)

            # Generate recommendations text
            recommendations_text = "\n\nHere are some workspace recommendations for you:\n\n"
            
            for idx, (_, row) in enumerate(df_filtered.head(10).iterrows(), 1):
                recommendations_text += f"{idx}. {row['Workspace Name']}"
                if pd.notna(row.get('Area')):
                    recommendations_text += f" ({row['Area']})"
                recommendations_text += f"\n"
                recommendations_text += f"Address: {row['Address']}\n"
                recommendations_text += f"Workspace Type: {row['Workspace Type']}\n"
                recommendations_text += f"Offerings: {row['Offerings']}\n"
                recommendations_text += f"Amenities: {row['Amenities']}\n"
                recommendations_text += f"Seats Available: {row['Seats Available']}\n"
                recommendations_text += f"Rating: {row['Rating']}\n"
                recommendations_text += f"Category: {row['Bundle']}\n"
                recommendations_text += f"Price: ₹{row['Price']}\n"
                if 'similarity_score' in row and pd.notna(row['similarity_score']):
                    recommendations_text += f"Similarity Score: {row['similarity_score']:.1f}%\n"
                recommendations_text += f"Link: [View Details]({row['Link']})\n\n"

            final_reply += recommendations_text
            
            # Generate and include Stylework URL
            workspace_info = extract_workspace_info_from_recommendations(recommendations_text)
            stylework_url = generate_stylework_url(workspace_info)
            
            if stylework_url:
                final_reply += f"\n🔗 **Browse more options:** {stylework_url}\n"
                print(f"[DEBUG] Generated Stylework URL: {stylework_url}")

        session.add_assistant_message(final_reply, {}, [])

    except Exception as e:
        print(f"[ERROR] Gemini chat failed: {e}")
        final_reply = "You can contact the operation team regarding this query at operations@stylework.city!"

    last_msg = session.get_messages()[-1] if session.get_messages() else {}
    timestamp = last_msg.get("timestamp") if last_msg else None

    return {"reply": final_reply, "timestamp": timestamp}

# Gemini agent for nearby places queries
NEARBY_PLACES_PROMPT = """
You are a helpful assistant that helps users find workspaces based on nearby places like cafes, restaurants, etc.
=======
                if workspace_id not in seen_workspaces and workspace_name:
                    seen_workspaces.add(workspace_id)
                    
                    category_value = str(row.get('CATEGORY AS PER PRICING', '')).strip().title()
                    
                    price_value = ""
                    if price_col and price_col in row:
                        price_value = row.get(price_col, '')
                    
                    rec = {
                        "name": workspace_name,
                        "address": workspace_address,
                        "workspace_type": workspace_type or "general",
                        "city": str(row.get('CITY', '')).strip(),
                        "area": str(row.get('AREA', '')).strip(),
                        "amenities": row.get('AMENITIES', []) if isinstance(row.get('AMENITIES'), list) else [],
                        "status": str(row.get('STATUS', '')).strip(),
                        "seats_available": row.get('seats_available', ''),
                        "rating": row.get('avg_rating', ''),
                        "category": category_value,
                        "price": price_value,
                        "offerings": str(row.get('Offering', '')),
                        "similarity_score": row.get('similarity_score', 0)
                    }
                    result.append(rec)
            
            # sort by price functionality
            sort_by_price = False
            sort_price_pattern = re.compile(
                r'\b(?:sort|order|arrange|filter)\s+(?:the\s+)?(?:.*?)(?:price|cost|rate|charges)\b',
                re.IGNORECASE
            )
            if sort_price_pattern.search(user_message):
                sort_by_price = True

            if sort_by_price and result:
                def get_price(rec):
                    try:
                        return float(rec.get('price', float('inf')))
                    except (ValueError, TypeError):
                        return float('inf')
                result = sorted(result, key=get_price)

            # sort by rating functionality 
            sort_by_rating = False
            sort_rating_pattern = re.compile(
                r'\b(?:sort|order|arrange|filter)\s+(?:the\s+)?(?:.*?)(?:rating)\b',
                re.IGNORECASE
            )
            if sort_rating_pattern.search(user_message):
                sort_by_rating = True

            if sort_by_rating and result:
                def get_rating(rec):
                    try:
                        return float(rec.get('rating', float('-inf')))
                    except (ValueError, TypeError):
                        return float('inf')
                result = sorted(result, key=get_rating, reverse=True)
            
            final_response = format_workspace_recommendations(result)
            stylework_url = generate_stylework_url(city, workspace_type, bundle, sort_by_price, budget)
            if stylework_url:
                final_response += f"\n🔗 **Browse more options:** {stylework_url}\n"
                print(f"[DEBUG] Generated Stylework URL: {stylework_url}")
            final_reply += final_response


        except Exception as e:
            print(f"Error in recommendation engine: {str(e)}")
            final_reply += "\n\nI understand your requirements, but encountered an issue while searching. Please try again."
    
    session.add_assistant_message(final_reply, response_metadata, tool_calls)
    # Get the last message (assistant) to extract its timestamp
    last_msg = session.get_messages()[-1] if session.get_messages() else None
    timestamp = last_msg.get("timestamp") if last_msg else None

    return {"reply": final_reply, "timestamp": timestamp}
    

# Gemini agent for nearby places queries
NEARBY_PROMPT = """
You are a helpful assistant that helps users find workspaces based on nearby places like cafes, restaurants, etc.
Your task is to analyze the user's query and determine:
1. Filter the workspaces based on the place type - using your own intellegence within 1km radius

Eg. There are multiple workspaces in df_filtered, if the place_type is "cafe", then filter the workspaces on the basis that which workspaces are closer to a cafe. So, return the workspaces that are closer to a cafe.

Respond in the following JSON format:
    {
        "Unboxed Coworking": "",
        "ADDRESS": "",
        "workspace_type": "",
        "CITY": "",
        "AREA": [""],
        "CATEGORY AS PER PRICING": "",
        "AMENITIES": [],
        "STATUS": "",
        "seats_available": 0,
        "avg_rating": 0,
        "Offering": ""
    }

Example queries and responses:

User: Show me workspaces near a cafe with good wifi
[
  {
    "Unboxed Coworking": "Innov8 Connaught Place",
    "ADDRESS": "Connaught Place, New Delhi",
    "workspace_type": "private cabin",
    "CITY": "delhi nct",
    "AREA": ["connaught place"],
    "CATEGORY AS PER PRICING": "private cabin",
    "AMENITIES": ["Wifi", "Cafeteria", "Reception"],
    "STATUS": "live",
    "seats_available": 10,
    "avg_rating": 4.5,
    "Offering": "private cabin"
  },
  {
    "Unboxed Coworking": "91springboard Nehru Place",
    "ADDRESS": "Nehru Place, New Delhi",
    "workspace_type": "private cabin",
    "CITY": "delhi nct",
    "AREA": ["nehru place"],
    "CATEGORY AS PER PRICING": "private cabin",
    "AMENITIES": ["Wifi", "Parking", "Reception"],
    "STATUS": "live",
    "seats_available": 5,
    "avg_rating": 4.2,
    "Offering": "private cabin"
  }
]

    so return the Unboxed Coworking, ADDRESS, workspace_type, CITY, AREA, AMENITIES, STATUS, seats_available, avg_rating, Offering of all the workspaces which are near the cafe from the dataset provided

IMPORTANT: Use the data from the dataset ONLY

"""

NEARBY_PLACES_PROMPT = """
You are a helpful assistant that helps users find workspaces based on nearby places like cafes, restaurants, metro stations etc.
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
Your task is to analyze the user's query and identify only the workspace names from the dataset that are near the given place type within 500m radius.

Respond with a JSON array of strings like: [Space Name 1, Space Name 2, .....]

<<<<<<< HEAD:backend.py
IMPORTANT: Use only the data from the dataset provided.
IMPORTANT: Maintain continuity with previous messages.
=======
Eg - User queries: Show me day pass in delhi near a cafe
["Innov8 Connaught Place", "91springboard Nehru Place"]

IMPORTANT: Use only the data from the dataset provided.
IMPORTANT: Maintain contunuity with previous messages.

>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
"""

async def parse_nearby_workspace(query: str, place_type: str, df_filtered: List[Dict], chat_history: List[Dict]) -> Dict[str, Any]:
    """Parse the workspaces about nearby places using Gemini."""
    try:
        # Initialize Gemini model
        model = genai.GenerativeModel('gemini-2.0-flash-lite')
        
        # Create the prompt
        prompt = f"""{NEARBY_PLACES_PROMPT}
        
        User query: {query}
        Place type: {place_type}
        Dataset: {df_filtered}
        Maintain continuity with previous messages
        Chat History: {chat_history}

        Respond with only the JSON array, no other text:"""
        
<<<<<<< HEAD:backend.py
        # Generate response
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        # Clean up response text
=======
        # Get response from Gemini
        response = model.generate_content(prompt)
        response_text = response.text.strip()

>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
        if response_text.startswith('```json'):
            response_text = response_text[response_text.find('['):response_text.rfind(']')+1]
        result = json.loads(response_text)
        print("[DEBUG] result: ", result)
        return result
    except Exception as e:
<<<<<<< HEAD:backend.py
        print(f"[ERROR] Nearby workspace parsing failed: {e}")
        return []

async def nearbyplaces_chat(user_message: str, df_filtered: pd.DataFrame, chat_history: List[Dict], session_id: str, user_id: str, place_type: str) -> Dict[str, Any]:
    """Handle nearby places queries and filter workspaces accordingly."""
=======
        print(f"Error parsing nearby query: {str(e)}")
        return []

@app.post("/api/nearbyplaces_chat")
async def nearbyplaces_chat(
    user_message: str = Body(..., embed=True),
    df_filtered: List[Dict] = Body(..., embed=True),
    chat_history: List[Dict] = Body([], embed=True),
    session_id: Optional[str] = Body(None, embed=True),
    user_id: Optional[str] = Body(None, embed=True),
    place_type: Optional[str] = Body(None, embed=True)
):
    """
    Endpoint to handle natural language queries about workspaces near specific places.
    Uses Gemini to understand the query and filter workspaces accordingly.
    """
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
    try:
        # Parse the user's query using Gemini
        filtered_results = await parse_nearby_workspace(user_message, place_type, df_filtered, chat_history)
        
        if not filtered_results:
<<<<<<< HEAD:backend.py
            return {"filtered_results": pd.DataFrame()}
        
        # Filter the dataframe to include only the workspaces mentioned by Gemini
        df_nearby = df_filtered[df_filtered['Workspace Name'].isin(filtered_results)]
        
        print(f"[DEBUG] Filtered {len(df_filtered)} workspaces to {len(df_nearby)} based on nearby places")
        
        return {"filtered_results": df_nearby}
        
    except Exception as e:
        print(f"[ERROR] Nearby places chat failed: {e}")
        return {"filtered_results": df_filtered}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
=======
            return {
                "filtered_results": df_filtered
            }

        matched_names = filtered_results  # now a list of names
        df = pd.DataFrame(df_filtered)
        df_filtered = df[df["Unboxed Coworking"].isin(matched_names)]
            
        if len(filtered_results) == 0:
            response_text = " However, no workspaces match all your criteria. Would you like to try different filters?"
        
        return {
            "filtered_results": df_filtered
        }
        
    except Exception as e:
        print(f"Error in nearbyplaces_chat: {str(e)}")
        return { 
            "filtered_results": df_filtered,
            "error": str(e)
        }
>>>>>>> 4917e2d (Add backend implementation and update frontend components):backend.txt
